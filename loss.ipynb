{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from data import ArgoDataset, collate_fn\n",
    "from utils import gpu, to_long,  Optimizer, StepLR\n",
    "\n",
    "from layers import Conv1d, Res1d, Linear, LinearRes, Null\n",
    "from numpy import float64, ndarray\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "from importlib import import_module\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Sampler, DataLoader\n",
    "\n",
    "\n",
    "from utils import Logger, load_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanegcn import get_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config, Dataset, collate_fn, net, loss, post_process, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(pid):\n",
    "    np_seed = int(pid)\n",
    "    np.random.seed(np_seed)\n",
    "    random_seed = np.random.randint(2 ** 32 - 1)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "dataset = Dataset('./dataset/preprocess/train_crs_dist6_angle90.p', config, train=True)\n",
    "train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        num_workers=config[\"workers\"],\n",
    "        shuffle=False,   # True: At each epoch, reorder the data\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=worker_init_fn,   # The next 36 were thrown away\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i, data in enumerate(train_loader):\n",
    "    data = dict(data)\n",
    "    break\n",
    "    \n",
    "\n",
    "\n",
    "print(data.keys())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gt_preds'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rel, out = net(data)\n",
    "traj_rel = out_rel['reg']\n",
    "traj = out['reg']\n",
    "print(traj_rel[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(traj_rel[0][0][0][:,0].detach().numpy(),traj_rel[0][0][0][:,1].detach().numpy())\n",
    "\n",
    "plt.scatter(traj[0][0][0][:,0].detach().numpy(),traj[0][0][0][:,1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanegcn import ActorNet, PredNet, MapNet, A2A, A2M, M2A, M2M, graph_gather, actor_gather\n",
    "pred_net = PredNet(config)\n",
    "\n",
    "actor_net = ActorNet(config)\n",
    "map_net = MapNet(config)\n",
    "a2m = A2M(config)\n",
    "m2m = M2M(config)\n",
    "m2a = M2A(config)\n",
    "a2a = A2A(config)\n",
    "\n",
    "# construct actor feature\n",
    "actors, actor_idcs = actor_gather(data[\"feats\"])\n",
    "actor_ctrs = data[\"ctrs\"]\n",
    "actors = actor_net(actors)\n",
    "# construct map features\n",
    "graph = graph_gather(to_long(data[\"graph\"]))\n",
    "nodes, node_idcs, node_ctrs = map_net(graph)\n",
    "nodes = a2m(nodes, graph, actors, actor_idcs, actor_ctrs)\n",
    "nodes = m2m(nodes, graph)\n",
    "actors = m2a(actors, actor_idcs, actor_ctrs, nodes, node_idcs, node_ctrs)\n",
    "actors = a2a(actors, actor_idcs, actor_ctrs)\n",
    "\n",
    "# prediction\n",
    "out = pred_net(actors, actor_idcs, actor_ctrs)\n",
    "rot, orig = data[\"rot\"], data[\"orig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.keys())\n",
    "traj = out['reg']\n",
    "plt.scatter(traj[0][0][0][:,0].detach().numpy(),traj[0][0][0][:,1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_copy(data):\n",
    "    if isinstance(data, list):\n",
    "        return [ref_copy(x) for x in data]\n",
    "    if isinstance(data, dict):\n",
    "        d = dict()\n",
    "        for key in data:\n",
    "            d[key] = ref_copy(data[key])\n",
    "        return d\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "out1 = dict()\n",
    "for key in ['reg', 'cls']:\n",
    "    if key in out:\n",
    "        out1[key] = ref_copy(out[key])\n",
    "\n",
    "for i in range(len(out[\"reg\"])):\n",
    "    out1[\"reg\"][i] = torch.matmul(out[\"reg\"][i], rot[i]) + orig[i].view(1, 1, 1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_rel = out['reg']\n",
    "traj = out1['reg']\n",
    "plt.scatter(traj_rel[0][0][0][:,0].detach().numpy(),traj_rel[0][0][0][:,1].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(traj[0][0][0][:,0].detach().numpy(),traj[0][0][0][:,1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanegcn import get_fake_traj_rel, get_pred_traj_rel\n",
    "fake_traj_rel = get_fake_traj_rel(data['traj1'], out['reg'])\n",
    "pred_traj_rel = get_pred_traj_rel(data['trajs2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanegcn import TrajectoryDiscriminator\n",
    "discriminator = TrajectoryDiscriminator(config)\n",
    "scores_real = discriminator(pred_traj_rel)\n",
    "scores_fake = discriminator(fake_traj_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores_real.size(), scores_fake.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rel, out = net(data)\n",
    "fake_traj_rel = get_fake_traj_rel(data['traj1'], out_rel['reg'])\n",
    "pred_traj_rel = get_pred_traj_rel(data['trajs2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_traj_rel.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fake_traj_rel[0][0,:].detach().numpy(), fake_traj_rel[0][1,:].detach().numpy())\n",
    "plt.scatter(pred_traj_rel[0][0,:].detach().numpy(), pred_traj_rel[0][1,:].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanegcn import TrajectoryDiscriminator\n",
    "discriminator = TrajectoryDiscriminator(config)\n",
    "\n",
    "scores_fake = discriminator(fake_traj_rel)\n",
    "scores_real = discriminator(pred_traj_rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import gan_d_loss\n",
    "# Compute loss with optional gradient penalty\n",
    "d_loss_fn = gan_d_loss\n",
    "losses = {}\n",
    "loss = torch.zeros(1)\n",
    "\n",
    "data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "losses['D_data_loss'] = data_loss.item()\n",
    "loss += data_loss\n",
    "losses['D_total_loss'] = loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=5e-4)\n",
    "\n",
    "optimizer_d.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "optimizer_d.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import gan_g_loss\n",
    "from lanegcn import Loss\n",
    "# g_loss\n",
    "def bce_loss(input, target):\n",
    "    neg_abs = -input.abs()\n",
    "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "    return loss.mean()\n",
    "    \n",
    "def gan_g_loss(scores_fake):\n",
    "    y_fake = torch.ones_like(scores_fake) * random.uniform(0.7, 1.2)\n",
    "    return bce_loss(scores_fake, y_fake)\n",
    "\n",
    "loss_fn = Loss(config)\n",
    "loss_out = loss_fn(out_rel, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {}\n",
    "loss = torch.zeros(1)\n",
    "\n",
    "losses['loss_reg_cls'] = loss_out[\"loss\"].item()\n",
    "\n",
    "\n",
    "\n",
    "g_loss_fn = gan_g_loss\n",
    "out_rel, out = net(data)\n",
    "fake_traj_rel = get_fake_traj_rel(data['traj1'], out_rel['reg'])\n",
    "pred_traj_rel = get_pred_traj_rel(data['trajs2'])\n",
    "scores_fake = discriminator(fake_traj_rel)\n",
    "scores_real = discriminator(pred_traj_rel)\n",
    "discriminator_loss = g_loss_fn(scores_fake)\n",
    "\n",
    "loss += loss_out[\"loss\"]\n",
    "loss += discriminator_loss\n",
    "\n",
    "losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "losses['G_total_loss'] = loss.item()\n",
    "\n",
    "optimizer_g = optim.Adam(net.parameters(), lr=5e-4)\n",
    "\n",
    "optimizer_g.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "optimizer_g.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('lanegcn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ff309fca0a5e8ad5576d7cf0da1773e4040ba62bb168e6dfb3b17a889a1e8a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
